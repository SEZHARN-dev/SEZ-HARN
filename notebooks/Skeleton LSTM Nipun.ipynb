{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31954,"status":"ok","timestamp":1684394023987,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"},"user_tz":-330},"id":"wWsazAElpznq","outputId":"a487c575-7687-4fa1-967d-4275c5540d66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Fvq_SNT4wtrt","executionInfo":{"status":"ok","timestamp":1684394029179,"user_tz":-330,"elapsed":5195,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"outputs":[],"source":["\n","import os \n","import random\n","import numpy as np\n","from tqdm import tqdm\n","import random\n","import copy\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","import shutil\n","\n","import torch \n","from torch import nn \n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","\n","# %matplotlib inline\n","# %config InlineBackend.figure_format='retina'\n","\n","# sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","# HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","# sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","# rcParams['figure.figsize'] = 12, 8"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"XFne_K8Kpxoa","executionInfo":{"status":"ok","timestamp":1684394029179,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"outputs":[],"source":["# pwd"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"z0tH3zkOpxoc","executionInfo":{"status":"ok","timestamp":1684394029180,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"outputs":[],"source":["# import tensorflow as tf\n","# print(tf.test.is_gpu_available())"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"J5Os0x_Qpxoc","scrolled":true,"executionInfo":{"status":"ok","timestamp":1684394029180,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"outputs":[],"source":["# ! pip install seaborn"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2gLseCaixj2Y","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1684394663905,"user_tz":-330,"elapsed":758,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}},"outputId":"ea86ff74-d126-40e1-a32c-e3d66cf82cbf"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e2a96b9e27ff>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test_key_arrays_npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrefined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Datasets\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sequence_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/FYP/key_arrays_npz/test_key_arrays_npz'"]}],"source":["# root_dir = \"C:\\\\Users\\\\yohan\\\\Desktop\\\\FYPCodes\\\\LSTM\"\n","main_dir = \"/content/gdrive/MyDrive/FYP/key_arrays_npz\"\n","data_dir = os.path.join(main_dir,\"test_key_arrays_npz\")\n","refined_data = os.path.join(main_dir,\"Datasets\",\"sequence_data\")\n","class_names = os.listdir(data_dir)\n","train_ratio = 0.8\n","val_ratio = 0.1\n","test_ratio = 1 - train_ratio - val_ratio\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMXd5j19IvTT"},"outputs":[],"source":["#shutil.rmtree(refined_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIP5EQEryQA6"},"outputs":[],"source":["file_list = []\n","\n","for class_n in os.listdir(data_dir):\n","    file_list += [os.path.join(data_dir,class_n,x) for x in os.listdir(os.path.join(data_dir,class_n))]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYcViWq8yZ3W","outputId":"fd329234-c348-4b91-95c1-f116b49f6cc4"},"outputs":[{"data":{"text/plain":["408"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(file_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiNVqGnpyb4r"},"outputs":[],"source":["def break_into_time_frames(coords,vid_size,time_window=50,stride=40):\n","    shape = coords.shape\n","    [h,w] = vid_size\n","    \n","    #[x,y,z] is the format\n","    if shape[0]<time_window:\n","        return None\n","    \n","    frame_points = list(range(0,shape[0]-time_window,stride))\n","    arrays = []\n","    for i in frame_points:\n","        arrays.append(coords[i:i+time_window])\n","    return arrays\n","\n","def save_arrays(data_dir,file_name,class_name,arrays,vid_size):\n","    for __id,each_array in enumerate(arrays):\n","        np.savez(os.path.join(data_dir,f\"{class_name}_cls_{file_name}_{__id}.npz\"),coords=each_array,video_size=vid_size)\n","\n","\n","def classname_id(class_name_list):\n","    id2classname = {k:v for k, v in zip(list(range(len(class_name_list))),class_name_list)}\n","    classname2id = {v:k for k, v in id2classname.items()}\n","    return id2classname, classname2id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDsxBhw7cKcQ"},"outputs":[],"source":["gen_required = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gaCMfVHKyfOW"},"outputs":[],"source":["if gen_required:\n","    os.makedirs(refined_data,exist_ok=True)\n","    for each_file in tqdm(file_list):\n","        a_file = np.load(each_file)\n","        coords, vid_size = a_file[\"coords\"],a_file[\"video_size\"]\n","        f_point = break_into_time_frames(coords,vid_size)\n","\n","        path_parts = each_file.strip().split(\"\\\\\")\n","        # print(path_parts)\n","        class_n = path_parts[-2]\n","        file_id = path_parts[-1].split(\".\")[0]\n","\n","        #print(class_n, file_id)\n","        if f_point:\n","            save_arrays(refined_data,file_id,class_n,f_point,vid_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfQ3SNCUyjIK","outputId":"e5205278-00b8-4ba5-dfb3-2db706baa1b5"},"outputs":[{"data":{"text/plain":["(898, (50, 33, 5))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(os.listdir(refined_data)),np.load(f\"{refined_data}\\\\0_cls_key_array_amani_back_1_0.npz\")[\"coords\"].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AGyBfJKyrLK"},"outputs":[],"source":["data_dir = refined_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9MHVsK7zFY3"},"outputs":[],"source":["id2clsname, clsname2id = classname_id(class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FWyqtCmzSkT"},"outputs":[],"source":["train_file_list = []\n","val_file_list = []\n","test_file_list = []\n","\n","file_list = [os.path.join(data_dir,x) for x in os.listdir(data_dir)]\n","\n","random.shuffle(file_list)\n","num_list = len(file_list)\n","\n","train_range = [0,int(num_list*train_ratio)]\n","val_range = [int(num_list*train_ratio),int(num_list*(train_ratio+val_ratio))]\n","test_range = [int(num_list*(train_ratio+val_ratio)),num_list-1]\n","\n","train_file_list += file_list[train_range[0]:train_range[1]]\n","val_file_list += file_list[val_range[0]:val_range[1]]\n","test_file_list += file_list[test_range[0]:test_range[1]]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArrBtSnhzVjm","outputId":"426ebb06-7984-4c2e-f882-a9b9b91cf5e4","scrolled":true},"outputs":[{"data":{"text/plain":["(628, 135, 134)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(train_file_list),len(val_file_list),len(test_file_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72A5WTGbzX40"},"outputs":[],"source":["# train_file_list = train_file_list[:(len(train_file_list)//batch_size)*batch_size]\n","# val_file_list = val_file_list[:(len(val_file_list)//batch_size)*batch_size]\n","# test_file_list = test_file_list[:(len(test_file_list)//batch_size)*batch_size]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ym9kfxwzaD8","outputId":"d2000ce6-4284-435f-d26f-4d3b7e5aa40a"},"outputs":[{"data":{"text/plain":["(608, 128, 128)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(train_file_list),len(val_file_list),len(test_file_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRGuhgzepxoj"},"outputs":[],"source":["# train_file_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwwdJqoNzcP_"},"outputs":[],"source":["class SkeletonDataset(Dataset):\n","    def __init__(self, file_list,class2id, transform=None, target_transform=None):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.class2id = class2id\n","        self.target_transform = target_transform\n","\n","    \n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        a_file = np.load(self.file_list[idx])\n","        action_type = self.file_list[idx].strip().split(\"\\\\\")[-1].split(\"_cls_\")[0]\n","        coords, vid_size = a_file[\"coords\"],a_file[\"video_size\"]\n","        \n","        shape = coords.shape\n","        \n","        coords = torch.from_numpy(coords).float()\n","        \n","        coords = torch.reshape(coords, (shape[0], shape[1]*shape[2]))\n","        label = torch.clone(coords)\n","        \n","        if self.transform:\n","            coords = self.transform(coords)\n","        if self.target_transform:\n","            label = self.target_transform(coords)\n","        return coords, label, self.class2id[action_type]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9W_8_Aqze-8"},"outputs":[],"source":["train_data = SkeletonDataset(train_file_list,clsname2id)\n","val_data = SkeletonDataset(val_file_list,clsname2id)\n","test_data = SkeletonDataset(test_file_list,clsname2id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZ1jmWihpxol","outputId":"e21bf134-c23a-4fef-968c-9ce3372b50d5"},"outputs":[{"data":{"text/plain":["<__main__.SkeletonDataset at 0x105bbd98be0>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REQXHK73zhWy"},"outputs":[],"source":["train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n","val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDFQpOGHzjMr"},"outputs":[],"source":["class BiLSTMEncoder(nn.Module):\n","    def __init__(self, input_size, hidden_size,device=None, num_layers = 1):\n","        super(BiLSTMEncoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        if device:\n","          self.device = device\n","        else:\n","          self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # define LSTM layer\n","        self.linear1 = nn.Linear(self.input_size, 128)\n","        self.linear2 = nn.Linear(128, 256)\n","        self.linear3 = nn.Linear(256, 512)\n","        self.lstm = nn.LSTM(input_size = 512, hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=True)\n","        \n","        \n","\n","    def forward(self, x_input):\n","        '''\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence                         \n","        '''\n","        \n","        x = self.linear1(x_input)\n","        x = self.linear2(x)\n","        x = self.linear3(x)\n","        \n","        lstm_out, self.hidden = self.lstm(x)\n","        hidden_transformed = torch.cat(self.hidden,0)\n","        hidden_transformed = torch.transpose(hidden_transformed,0,1)\n","        hidden_transformed = torch.flatten(hidden_transformed,start_dim=1)\n","        \n","        return lstm_out, hidden_transformed.to(self.device)\n","    \n","class BiLSTMDecoder(nn.Module):\n","    def __init__(self, input_size, hidden_size,device=None, num_layers = 1):\n","        super(BiLSTMDecoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        if device:\n","          self.device = device\n","        else:\n","          self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # define LSTM layer\n","        self.linear1 = nn.Linear(128, self.input_size)\n","        self.linear2 = nn.Linear(256, 128)\n","        self.linear3 = nn.Linear(512, 256)\n","        self.linear4 = nn.Linear(1024, 512)\n","        \n","        self.lstm = nn.LSTM(input_size = 512, hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=True)\n","        \n","        \n","\n","    def forward(self,encoder_hidden):\n","        '''\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence                         \n","        '''\n","        \n","        hidden_shape = encoder_hidden.shape\n","        \n","        hidden = encoder_hidden.view((hidden_shape[0],4,512))\n","        hidden = torch.transpose(hidden,1,0)\n","        h1,h2,c1,c2 = torch.unbind(hidden,0)\n","        h,c = torch.stack((h1,h2)),torch.stack((c1,c2))\n","        \n","        dummy_input = torch.rand((32,50,512), requires_grad=True)\n","        \n","        lstm_out, self.hidden = self.lstm(dummy_input,(h,c))\n","        x = self.linear4(lstm_out)\n","        x = self.linear3(x)\n","        x = self.linear2(x)\n","        x = self.linear1(x)\n","        \n","        return x\n","\n","class BiLSTMEncDecModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers = 1):\n","        super(BiLSTMEncDecModel, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        \n","        self.encoder = BiLSTMEncoder(input_size,hidden_size,self.device)\n","        self.decoder = BiLSTMDecoder(input_size,hidden_size,self.device)\n","        \n","    def forward(self,x):\n","        lstm_out,embedding = self.encoder(x)\n","        embedding = embedding.to(self.device)\n","        decoder_out = self.decoder(embedding)\n","        \n","        return decoder_out\n","        \n","\n","        \n","        \n","        \n","        \n","        \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAg3zXChznPg","outputId":"f9437ba8-5301-4751-a471-fe61c6e74dd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["165\n","165\n"]}],"source":["encoder = BiLSTMEncoder(165,512)\n","decoder = BiLSTMDecoder(165,512)\n","\n","bilstm_model = BiLSTMEncDecModel(165,512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XWqsEhpzqEq"},"outputs":[],"source":["lstm_out, embedding = encoder(torch.randn((32, 50, 165)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"an_K4SoGzsrA"},"outputs":[],"source":["decoder_out = decoder(embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCK5c4l2zuzm","outputId":"a4d2f828-0a40-4c5f-ba19-02ecdddba9de"},"outputs":[{"data":{"text/plain":["torch.Size([32, 50, 165])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["model_out = bilstm_model(torch.randn((32, 50, 165)))\n","model_out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MN40e6xfz1zF"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wz8JfCZ2z4Bv"},"outputs":[],"source":["def train_model(model, train_dataset, val_dataset, n_epochs):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    std_loss = nn.L1Loss(reduction='sum').to(device)\n","    #contrastive_loss = SupConLoss(contrast_mode=\"one\").to(device)\n","    history = dict(train=[], val=[])\n","    model.to(device)\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = 10000.0\n","  \n","    for epoch in range(1, n_epochs + 1):\n","        model = model.train()\n","\n","        train_losses = []\n","        for in_seq,tar_seq,action in tqdm(train_dataset):\n","            optimizer.zero_grad()\n","            \n","            in_seq = in_seq.to(device)\n","            tar_seq = tar_seq.to(device)\n","            # print(in_seq.shape)\n","            seq_pred = model(in_seq)\n","            \n","            loss = std_loss(seq_pred, tar_seq)\n","            #loss += 0.5*contrastive_loss(embed,labels=sample_label.view(-1))\n","            #print(contrastive_loss(embed,labels=sample_label.view(-1)))\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_losses.append(loss.item())\n","\n","        val_losses = []\n","        model = model.eval()\n","        with torch.no_grad():\n","            for in_seq,tar_seq,action in val_dataset:\n","\n","                in_seq = in_seq.to(device)\n","                tar_seq = tar_seq.to(device)\n","                seq_pred = model(in_seq)\n","\n","                loss = std_loss(seq_pred, tar_seq)\n","                #loss += 0.5*contrastive_loss(embed,labels=sample_label.view(-1))\n","                val_losses.append(loss.item())\n","\n","        train_loss = np.mean(train_losses)\n","        val_loss = np.mean(val_losses)\n","\n","        history['train'].append(train_loss)\n","        history['val'].append(val_loss)\n","\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","\n","    model.load_state_dict(best_model_wts)\n","    return model.eval(), history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"Cw5XSsFCz6DV","outputId":"bd89177d-ec77-49a4-b336-8402dc7cc340"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [11:36<00:00, 36.68s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: train loss 109501.10793585527 val loss 75158.12109375\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [11:40<00:00, 36.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2: train loss 60833.11287006579 val loss 60649.8564453125\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [12:07<00:00, 38.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3: train loss 40704.39946546053 val loss 31644.11572265625\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [11:55<00:00, 37.66s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4: train loss 26256.50699013158 val loss 28766.04052734375\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [11:55<00:00, 37.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5: train loss 26216.98365542763 val loss 29450.6748046875\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█████████████                                                                      | 3/19 [02:37<13:58, 52.40s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbilstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[54], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, val_dataset, n_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m std_loss(seq_pred, tar_seq)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#loss += 0.5*contrastive_loss(embed,labels=sample_label.view(-1))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#print(contrastive_loss(embed,labels=sample_label.view(-1)))\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     30\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model, history = train_model(\n","  bilstm_model, \n","  train_dl, \n","  val_dl, \n","  n_epochs=500\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2MAWAEbpxop","outputId":"c4bae864-5f6d-4b6e-940b-d0e81494e2aa"},"outputs":[{"data":{"text/plain":["['model\\\\bilstm_model_1.joblib']"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","\n","joblib.dump(bilstm_model,'model\\\\bilstm_model_1.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2G4RzOS2pxoq"},"outputs":[],"source":["bilstm = joblib.load('model\\\\bilstm_model_1.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDTRPufXpxoq","outputId":"18dec63b-2fa7-4f4c-87a3-77749be3d40a"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:01<00:00, 10.16it/s]\n"]}],"source":["for in_seq,tar_seq,action in tqdm(train_dl):\n","    in_seq = in_seq.to(device)\n","    tar_seq = tar_seq.to(device)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XFc5tLG1pxoq"},"outputs":[],"source":["x = np.load('C:\\\\Users\\\\yohan\\\\Desktop\\\\FYPData\\\\key_arrays_npz\\\\test_key_arrays_npz_all\\\\key_array_amani_back_1.npz')[\"coords\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7Gl0SQFpxor","outputId":"84ca1ee5-e8d8-4ee7-d6d5-f411aceb2776"},"outputs":[{"data":{"text/plain":["(118, 33, 5)"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["x.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SE_MzU70pxor","outputId":"86066f89-438d-4d94-df79-99edf6ae4e5d"},"outputs":[{"data":{"text/plain":["torch.Size([32])"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["action.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqpNJgZxpxor","outputId":"b11eed0e-c113-4451-a9f7-afa24d7d746f"},"outputs":[{"data":{"text/plain":["torch.Size([165])"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["tar_seq[0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQAJKqzWpxor","outputId":"cc17cea5-5343-4cde-9338-a3efd8e17032"},"outputs":[{"data":{"text/plain":["torch.Size([32, 50, 165])"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["in_seq.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6-O6Llypxo1"},"outputs":[],"source":["lstm_out, embedding = encoder(in_seq[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qs0DAdhpxo1","outputId":"e0afcff5-a7d6-40c8-8dc0-134049eacf2d"},"outputs":[{"data":{"text/plain":["torch.Size([50, 1024])"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["lstm_out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srC5MX6rpxo1","outputId":"82cf54fa-a8af-4cf2-e153-e7363af923a6"},"outputs":[{"data":{"text/plain":["torch.Size([512, 4])"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["embedding.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXg9s2YCpxo1"},"outputs":[],"source":["l = bilstm_model(in_seq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoPxAGrapxo1","outputId":"2ce5e40f-350e-470c-93b8-7b558eac5e2a"},"outputs":[{"data":{"text/plain":["torch.Size([32, 50, 165])"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["l.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruxZSj5Az_eQ"},"outputs":[],"source":["ax = plt.figure().gca()\n","\n","ax.plot(history['train'])\n","ax.plot(history['val'])\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['train', 'test'])\n","plt.title('Loss over training epochs')\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQRrSLfd0B_w"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1ZxWYLeSD96SxuEu6-XyPW2sE3ltvfZc5","timestamp":1684393945161}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}