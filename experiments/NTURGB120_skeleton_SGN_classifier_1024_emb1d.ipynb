{"cells":[{"cell_type":"code","source":["! pip install neptune\n","! git clone https://github.com/nipdep/HAR-ZSL-XAI.git --branch AE --single-branch\n","! mv /content/HAR-ZSL-XAI/AETraining/dataset /content/"],"metadata":{"id":"Nl_KaA2qzl1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":429,"status":"error","timestamp":1684244671732,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"BkIfhXqxWhOw","outputId":"28cd66bb-ca60-4bb4-de66-17e554eeb418"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1f9cec90e964>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneptune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neptune'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import neptune\n","\n","from itertools import product\n","import torch \n","from torch import nn \n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm.autonotebook import tqdm\n","import itertools\n","import random\n","import copy\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","import cv2\n","import json\n","from sklearn.model_selection import train_test_split\n","from functools import partial\n","from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\",\n","                        \"#FFDD00\",\n","                        \"#FF7D00\",\n","                        \"#FF006D\",\n","                        \"#ADFF02\",\n","                        \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","rcParams['figure.figsize'] = 12, 8\n","\n","\n","\"\"\"\n","Collection of functions which enable the evaluation of a classifier's performance,\n","by showing confusion matrix, accuracy, recall, precision etc.\n","\"\"\"\n","\n","import numpy as np\n","import sys\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn import metrics\n","from tabulate import tabulate\n","import math\n","import logging\n","from datetime import datetime\n","from sklearn.metrics import accuracy_score\n","\n","def save_history(history, model_name, unique_name, models_saves, config):\n","    PATH = f\"{models_saves}/{model_name}\"\n","    os.makedirs(PATH, exist_ok=True)\n","\n","    with open(f\"{PATH}/{unique_name}.json\", \"w+\") as f0:\n","        json.dump(history, f0)\n","\n","def get_config(file_loc):\n","    file = torch.load(file_loc)\n","    return file[\"model_state_dict\"], file[\"model_config\"], file[\"config\"]\n","    \n","def save_model(model, model_name, unique_name, models_saves, config):\n","    PATH = f\"{models_saves}/{model_name}\"\n","    os.makedirs(PATH, exist_ok=True)\n","    torch.save({\n","        \"n_epochs\": config[\"n_epochs\"],\n","        \"model_state_dict\": model.state_dict(),\n","        \"model_config\": config[\"model\"],\n","        \"config\": config\n","    }, f\"{PATH}/{unique_name}.pt\")\n","\n","def plot_confusion_matrix(ConfMat, label_strings=None, title='Confusion matrix', cmap=plt.cm.get_cmap('Blues')):\n","    \"\"\"Plot confusion matrix in a separate window\"\"\"\n","    plt.imshow(ConfMat, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    if label_strings:\n","        tick_marks = np.arange(len(label_strings))\n","        plt.xticks(tick_marks, label_strings, rotation=90)\n","        plt.yticks(tick_marks, label_strings)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def generate_classification_report(existing_class_names, precision, recall, f1, support, ConfMatrix_normalized_row, digits=3, number_of_thieves=2, maxcharlength=35):\n","    \"\"\"\n","    Returns a string of a report for given metric arrays (array length equals the number of classes).\n","    Called internally by `analyze_classification`.\n","        digits: number of digits after . for displaying results\n","        number_of_thieves: number of biggest thieves to report\n","        maxcharlength: max. number of characters to use when displaying thief names\n","    \"\"\"\n","\n","    relative_freq = support / np.sum(support)  # relative frequencies of each class in the true lables\n","    sorted_class_indices = np.argsort(relative_freq)[\n","                            ::-1]  # sort by \"importance\" of classes (i.e. occurance frequency)\n","\n","    last_line_heading = 'avg / total'\n","\n","    width = max(len(cn) for cn in existing_class_names)\n","    width = max(width, len(last_line_heading), digits)\n","\n","    headers = [\"precision\", \"recall\", \"f1-score\", \"rel. freq.\", \"abs. freq.\", \"biggest thieves\"]\n","    fmt = '%% %ds' % width  # first column: class name\n","    fmt += '  '\n","    fmt += ' '.join(['% 10s' for _ in headers[:-1]])\n","    fmt += '|\\t % 5s'\n","    fmt += '\\n'\n","\n","    headers = [\"\"] + headers\n","    report = fmt % tuple(headers)\n","    report += '\\n'\n","\n","    for i in sorted_class_indices:\n","        values = [existing_class_names[i]]\n","        for v in (precision[i], recall[i], f1[i],\n","                    relative_freq[i]):  # v is NOT a tuple, just goes through this list 1 el. at a time\n","            values += [\"{0:0.{1}f}\".format(v, digits)]\n","        values += [\"{}\".format(support[i])]\n","        thieves = np.argsort(ConfMatrix_normalized_row[i, :])[::-1][\n","                    :number_of_thieves + 1]  # other class indices \"stealing\" from class. May still contain self\n","        thieves = thieves[thieves != i]  # exclude self at this point\n","        steal_ratio = ConfMatrix_normalized_row[i, thieves]\n","        thieves_names = [\n","            existing_class_names[thief][:min(maxcharlength, len(existing_class_names[thief]))] for thief\n","            in thieves]  # a little inefficient but inconsequential\n","        string_about_stealing = \"\"\n","        for j in range(len(thieves)):\n","            string_about_stealing += \"{0}: {1:.3f},\\t\".format(thieves_names[j], steal_ratio[j])\n","        values += [string_about_stealing]\n","\n","        report += fmt % tuple(values)\n","\n","    report += '\\n' + 100 * '-' + '\\n'\n","\n","    # compute averages/sums\n","    values = [last_line_heading]\n","    for v in (np.average(precision, weights=relative_freq),\n","                np.average(recall, weights=relative_freq),\n","                np.average(f1, weights=relative_freq)):\n","        values += [\"{0:0.{1}f}\".format(v, digits)]\n","    values += ['{0}'.format(np.sum(relative_freq))]\n","    values += ['{0}'.format(np.sum(support))]\n","    values += ['']\n","\n","    # make last (\"Total\") line for report\n","    report += fmt % tuple(values)\n","\n","    return report\n","\n","\n","def action_evaluator(y_pred, y_true, class_names, excluded_classes=None, maxcharlength=35, print_report=True, show_plot=True):\n","    \"\"\"\n","    For an array of label predictions and the respective true labels, shows confusion matrix, accuracy, recall, precision etc:\n","    Input:\n","        y_pred: 1D array of predicted labels (class indices)\n","        y_true: 1D array of true labels (class indices)\n","        class_names: 1D array or list of class names in the order of class indices.\n","            Could also be integers [0, 1, ..., num_classes-1].\n","        excluded_classes: list of classes to be excluded from average precision, recall calculation (e.g. OTHER)\n","    \"\"\"\n","\n","    # Trim class_names to include only classes existing in y_pred OR y_true\n","    in_pred_labels = set(list(y_pred))\n","    in_true_labels = set(list(y_true))\n","    # print(\"predicted labels > \", in_pred_labels, \"in_true_labels > \", in_true_labels)\n","\n","    existing_class_ind = sorted(list(in_pred_labels | in_true_labels))\n","    # print(\"pred label\", in_pred_labels, \"true label\", in_true_labels)\n","    class_strings = [str(name) for name in class_names]  # needed in case `class_names` elements are not strings\n","    existing_class_names = [class_strings[ind][:min(maxcharlength, len(class_strings[ind]))] for ind in existing_class_ind]  # a little inefficient but inconsequential\n","\n","    # Confusion matrix\n","    ConfMatrix = metrics.confusion_matrix(y_true, y_pred)\n","\n","    # Normalize the confusion matrix by row (i.e by the number of samples in each class)\n","    ConfMatrix_normalized_row = metrics.confusion_matrix(y_true, y_pred, normalize='true') \n","\n","    if show_plot:\n","        plt.figure()\n","        plot_confusion_matrix(ConfMatrix_normalized_row, label_strings=existing_class_names,\n","                                title='Confusion matrix normalized by row')\n","        plt.show(block=False)\n","\n","    # Analyze results\n","    total_accuracy = np.trace(ConfMatrix) / len(y_true)\n","    print('Overall accuracy: {:.3f}\\n'.format(total_accuracy))\n","\n","    # returns metrics for each class, in the same order as existing_class_names\n","    precision, recall, f1, support = metrics.precision_recall_fscore_support(y_true, y_pred, labels=existing_class_ind, zero_division=0)\n","    # Print report\n","    if print_report:\n","        print(generate_classification_report(existing_class_names, precision, recall, f1, support, ConfMatrix_normalized_row))\n","\n","    # Calculate average precision and recall\n","    # prec_avg, rec_avg = get_avg_prec_recall(ConfMatrix, existing_class_names, excluded_classes)\n","    # if excluded_classes:\n","    #     print(\n","    #         \"\\nAverage PRECISION: {:.2f}\\n(using class frequencies as weights, excluding classes with no predictions and predictions in '{}')\".format(\n","    #             prec_avg, ', '.join(excluded_classes)))\n","    #     print(\n","    #         \"\\nAverage RECALL (= ACCURACY): {:.2f}\\n(using class frequencies as weights, excluding classes in '{}')\".format(\n","    #             rec_avg, ', '.join(excluded_classes)))\n","\n","    # Make a histogram with the distribution of classes with respect to precision and recall\n","    # prec_rec_histogram(precision, recall)\n","\n","    return {\"accuracy\": total_accuracy, \"precision\": precision.mean(), \"recall\": recall.mean(), \"f1\": f1.mean()}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671733,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"p0XIAvcQX3l0"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def classname_id(class_name_list):\n","    id2classname = {k:v for k, v in zip(list(range(len(class_name_list))),class_name_list)}\n","    classname2id = {v:k for k, v in id2classname.items()}\n","    return id2classname, classname2id"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671734,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"y7gAeWUDX7X6"},"outputs":[],"source":["model_ident = \"NTURGB120_skeleton_SGN_classifier_emb1d\"\n","unique_iden = \"epoch50_emb400_xy\"\n","\n","main_dir = \"..\"\n","data_dir = os.path.join(\"H:\\\\Academics\\\\FYP_data\")\n","remove_files = [\"H:\\\\Academics\\\\FYP_data\\\\NTU_RGBD120_samples_with_missing_skeletons.txt\",\n","                \"H:\\\\Academics\\\\FYP_data\\\\NTU_RGBD_samples_with_missing_skeletons.txt\"]\n","\n","epoch_vids = os.path.join(main_dir,\"epoch_vids\")\n","models_saves = os.path.join(main_dir,\"model_saves\")\n","embeddings_save = os.path.join(main_dir,\"embedding_save\")\n","prototypes_save = os.path.join(main_dir,\"prototypes\")\n","test_vids = os.path.join(main_dir,\"test_vids\")\n","train_ratio = 0.90\n","val_ratio = 0.1\n","batch_size = 32\n","\n","os.makedirs(epoch_vids,exist_ok=True)\n","os.makedirs(models_saves,exist_ok=True)\n","os.makedirs(embeddings_save,exist_ok=True)\n","\n","with open(\"H:\\\\Academics\\\\FYP_data\\\\nturgb120_label_map.json\",\"r\") as f0:\n","    full_id2cls = json.load(f0)\n","    \n","with open(\"H:\\\\Academics\\\\FYP_data\\\\sel_cls_list - Single_person.txt\",\"r\") as f0:\n","    class_names = [full_id2cls[x] for x in f0.read().split(\" \")]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671734,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"IrsB7xhhaKF5"},"outputs":[],"source":["config = {\n","    \"n_epochs\":20,\n","    \"model_name\":\"BidirectionalLSTM\",\n","    \"model\":{\n","        \"num_joint\":12,\n","        \"seq_len\":50,\n","        \"decoder_hidden_size\":1024,\n","        \"linear_filters\":[128,256,512,1024],\n","        \"embedding_size\":400,\n","        \"num_classes\":len(class_names),\n","        \"num_layers\":1,\n","        \"is_3d\":False,\n","        \"bidirectional\":True,\n","        \"batch_size\":batch_size,\n","        \"dev\":device\n","        },\n","    \"lr\":1e-4,\n","    'alpha_target': 0.9\n","}\n","\n","config[\"model\"][\"encoder_hidden_size\"] = config[\"model\"][\"embedding_size\"]//2\n","config[\"model\"][\"input_size\"] = config[\"model\"][\"num_joint\"]*3 if config[\"model\"][\"is_3d\"] else config[\"model\"][\"num_joint\"]*2\n","\n","id2clsname, clsname2id = classname_id(class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671734,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"bziGM7xoEgPz"},"outputs":[],"source":["run = neptune.init_run(\n","    project=\"FYP-Group22/ICANN-Logs\",\n","    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkNWJjMDdhNC05NWY5LTQwNWQtYTQyNi0zNjNmYmYwZDg3M2YifQ==\",\n",")  # your credentials\n","\n","run['parameters'] = config"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671735,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"PrpFnUcsHcDo"},"outputs":[],"source":["config"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671735,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"25RyOW-8gA46"},"outputs":[],"source":["from dataset.SkeletonData.data import *\n","\n","with open(\"H:\\\\Academics\\\\FYP_data\\\\shapes_keys.json\",\"r\") as f0:\n","    id2shapes = json.load(f0)\n","\n","with open(\"H:\\\\Academics\\\\FYP_data\\\\id_list.txt\",\"r\") as f0:\n","    id_list = f0.read().strip().split(\"\\n\")\n","\n","files_to_remove = set()\n","for __f in remove_files:\n","    with open(__f,\"r\") as f0:\n","        for val in f0.read().split(\"\\n\"):\n","            files_to_remove.add(val)\n","\n","print(\"Number of Files to remove:= \",len(files_to_remove))\n","\n","total_files = set([x.split(\".\")[0] for x in id_list]) - files_to_remove\n","total_files_loc = set([f\"{os.path.join(data_dir,x)}.skeleton\" for x in total_files])\n","\n","#split list\n","rows = [(full_id2cls[str(int(x.split(\".\")[0][-3:]))],x) for x in total_files_loc]\n","info_pd = pd.DataFrame(data=rows,columns=[\"target\",\"file_loc\"])\n","\n","#select needed classes.\n","info_pd = info_pd.loc[info_pd[\"target\"].isin(class_names)]\n","train_df, val_df = train_test_split(info_pd,stratify=info_pd[\"target\"],train_size=train_ratio)\n","\n","print(\"Number of Files to Total:= \",len(total_files))\n","\n","train_builder = SkeletonFileBuilder(file_names=set(train_df[\"file_loc\"].to_list()),ignore_files=remove_files)\n","val_builder = SkeletonFileBuilder(file_names=set(val_df[\"file_loc\"].to_list()),ignore_files=remove_files)\n","\n","print(\"Number of Files to Train:= \",len(train_builder))\n","print(\"Number of Files to Val:= \",len(val_builder))\n","\n","train_file_iterator = iter(train_builder)\n","val_file_iterator = iter(val_builder)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671735,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"Res0UAsOjjki"},"outputs":[],"source":["def load_file_to_memory(id2shape,save_dict,each_file):\n","  file_id = each_file.filepath.split(os.path.sep)[-1].split(\".\")[0]\n","  #if not os.path.exists(f\"{data_dir}/{file_id}.skeleton\"):\n","  #  return None\n","\n","  num_frame, body_data = each_file.load_data()\n","  orig_vid_size = id2shape[file_id]\n","  \n","  #for frame_data in body_data:\n","  #  if frame_data[\"body_count\"] != 1:\n","  #      return None\n","  \n","  skel_data = []\n","  for frame_data in body_data:\n","      frame_jd = []\n","      for jd in frame_data[\"bodies\"][0][\"joint_details\"]:\n","          x = jd[\"colorX\"] / orig_vid_size[1]\n","          y = jd[\"colorY\"] / orig_vid_size[0]\n","\n","          frame_jd.append([x, y])\n","\n","      skel_data.append(frame_jd)\n","\n","  skel_data = np.asarray(skel_data)\n","  save_dict[file_id] = (file_id,orig_vid_size,str(int(file_id[-3:])),skel_data)\n","  return file_id\n","\n","class SkeletonDataset(Dataset):\n","    def __init__(self,\n","                 data_builder, \n","                 fileid2shape,\n","                 full_label_map,\n","                 cls2id,\n","                 data=None,\n","                 transform=None,\n","                 seq_len = 100,\n","                 window_size = 200,\n","                 target_transform=None,\n","                 active_locations=[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28],\n","                 file_name=False, \n","                 is_2d=False):\n","        self.data_builder = data_builder\n","        self.data = data\n","        self.transform = transform\n","        self.fileid2shape = fileid2shape\n","        self.window_size = window_size\n","        self.seq_len = seq_len\n","        self.target_transform = target_transform\n","        self.active_locations = active_locations\n","        self.file_name = file_name\n","        self.is_2d = is_2d\n","        self.cls2id = cls2id\n","        self.full_label_map = full_label_map\n","\n","        if self.active_locations:\n","          self.join_translation_map = {k:i for i,k in enumerate(self.active_locations)}\n","        \n","        if not self.data:\n","          self.data = {}\n","          with ThreadPoolExecutor() as executor:\n","            self.indexes = list(\n","                tqdm(\n","                  executor.map(\n","                    partial(load_file_to_memory,self.fileid2shape,self.data),\n","                    self.data_builder), \n","                  total=len(self.data_builder),\n","                  desc=\"Loaded Files\"\n","                )\n","            )\n","\n","          self.full_indexes = [x for x in self.indexes if x != None]\n","        else:\n","          self.full_indexes = list(self.data.keys())\n","          \n","        self.indexes = random.sample(self.full_indexes,(len(self.full_indexes)//batch_size)*batch_size)\n","    \n","\n","    def __len__(self):\n","        return len(self.indexes)\n","      \n","    def select_frames(self,sequence):\n","      if sequence.shape[0]<self.seq_len:\n","        times = self.seq_len//sequence.shape[0] + 1\n","\n","        sequence = sequence.repeat(times,1,1)\n","\n","      if sequence.shape[0]>self.window_size:\n","        start = random.randint(0,sequence.shape[0]-self.window_size-1)\n","        sequence = sequence[start:start+self.window_size,...]\n","                               \n","      sel_index = sorted(random.sample(range(sequence.shape[0]),self.seq_len))\n","        \n","      return sequence[sel_index,...]\n","    \n","    def create_connection_map(self,original_map):\n","      if not self.active_locations:\n","        return original_map\n","      \n","      all_possible_comb = product(self.active_locations,self.active_locations)\n","      all_possible_comb = set(all_possible_comb)\n","      \n","      original_map = set(original_map)\n","      sel_connections = list(all_possible_comb.intersection(original_map))\n","      sel_connections = [(self.join_translation_map[x[0]],self.join_translation_map[x[1]]) for x in sel_connections]\n","      \n","      return sel_connections \n","\n","    def __getitem__(self, idx):\n","        idx = self.indexes[idx]\n","        \n","        orig_target = self.data[idx][2]\n","        file_path = self.data[idx][0]\n","        vid_size = self.data[idx][1]\n","        coords = self.data[idx][3]\n","        \n","        target = self.cls2id[self.full_label_map[orig_target]]\n","        \n","        if self.active_locations:\n","          coords = coords[:,self.active_locations,:]\n","\n","        if self.is_2d:\n","            coords = coords[...,0:2]\n","\n","        coords = torch.from_numpy(coords).float()\n","        coords = self.select_frames(coords)\n","\n","        shape = coords.shape\n","        coords = torch.reshape(coords, (shape[0], shape[1]*shape[2]))\n","        label = torch.clone(coords)\n","\n","        if self.transform:\n","            coords = self.transform(coords)\n","        if self.target_transform:\n","            label = self.target_transform(coords)\n","\n","        coords[torch.isnan(coords)] = 0\n","        label[torch.isnan(label)] = 0\n","\n","        if self.file_name:\n","            return coords, label, target,vid_size,file_path\n","        return coords, label, target,vid_size"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671735,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"zLF82zVTWDnw"},"outputs":[],"source":["with open(\"H:\\\\Academics\\\\FYP_data\\\\train_data.pkl\",\"rb\") as f0:\n","  train_data_load = pickle.load(f0)\n","\n","with open(\"H:\\\\Academics\\\\FYP_data\\\\val_data.pkl\",\"rb\") as f0:\n","  val_data_load = pickle.load(f0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671735,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"o0Mlr88WEjWt"},"outputs":[],"source":["train_ds = SkeletonDataset(train_file_iterator,\n","                             id2shapes,\n","                             full_id2cls,\n","                             clsname2id,\n","                             data=train_data_load,\n","                             seq_len=config[\"model\"][\"seq_len\"],\n","                             file_name=True,\n","                             is_2d=True,\n","                             active_locations=[10,9,8,4,5,6,\n","                                               16,17,18,12,13,14])\n","val_ds = SkeletonDataset(val_file_iterator,\n","                           id2shapes,\n","                           full_id2cls,\n","                           clsname2id,\n","                           data=val_data_load,\n","                           seq_len=config[\"model\"][\"seq_len\"],\n","                           file_name=True,\n","                           is_2d=True,\n","                           active_locations=[10,9,8,4,5,6,\n","                                               16,17,18,12,13,14])\n","#test_data = SkeletonDataset(val_file_iterator,id2shapes,is_2d=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"iThGfDYvch4Q"},"outputs":[],"source":["len(train_ds.indexes),len(val_ds.indexes)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"B6mtux6OEmIk"},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n","#test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"gv4MRtlZbLYt"},"outputs":[],"source":["def gen_skeleton(frame, \n","                 height,\n","                 width,\n","                 mapping_list = [(0, 1), (1, 3), (3, 5), \n","                                 (0, 2), (2, 4), (0, 6), \n","                                 (1, 7), (6, 7), (6, 8), \n","                                 (7, 9), (8, 10), (9, 11)]):\n","    img_3 = np.zeros([height, width,3],dtype=np.uint8)\n","    img_3.fill(255)\n","\n","    # add circles\n","    for coord in frame:\n","        x, y = int(width*coord[0]), int(height*coord[1])\n","        img_3 = cv2.circle(img_3, center=(x,y), radius=1, color=(255, 0, 0), thickness=6)\n","\n","    # add lines\n","    for line in mapping_list:\n","        i, j = line\n","        st = frame[i, :]\n","        start_point = (int(width*st[0]), int(height*st[1]))\n","\n","        en = frame[j, :]\n","        end_point = (int(width*en[0]), int(height*en[1]))\n","\n","        img3_ = cv2.line(img_3, start_point, end_point, color=(0, 0, 0), thickness=3)\n","\n","    return img_3\n","\n","def gen_video(points, \n","              save_file, \n","              frame_h, \n","              frame_w, \n","              is_3d=True,\n","              mapping_list = [(0, 1), (1, 3), (3, 5), \n","                                 (0, 2), (2, 4), (0, 6), \n","                                 (1, 7), (6, 7), (6, 8), \n","                                 (7, 9), (8, 10), (9, 11)]):\n","    # make 3D if points are flatten\n","    if len(points.shape) == 2:\n","        if is_3d:\n","          fts = points.shape[1]\n","          x_cds = list(range(0, fts, 3))\n","          y_cds = list(range(1, fts, 3))\n","          z_cds = list(range(2, fts, 3))\n","          points = np.transpose(np.array([points[:, x_cds], \n","                                          points[:, y_cds], \n","                                          points[:, z_cds]]), (1,2,0))\n","        else:\n","          fts = points.shape[1]\n","          x_cds = list(range(0, fts, 2))\n","          y_cds = list(range(1, fts, 2))\n","          points = np.transpose(np.array([points[:, x_cds], \n","                                          points[:, y_cds]]), (1,2,0))\n","\n","    size = (frame_w, frame_h)\n","    result = cv2.VideoWriter(save_file,\n","                         cv2.VideoWriter_fourcc(*'MJPG'),\n","                         10, size)\n","\n","    for __id,frame in enumerate(points):\n","        skel_image = gen_skeleton(frame, frame_h, frame_w,mapping_list=mapping_list)\n","        result.write(skel_image)\n","\n","    result.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"kpiMgL96h1ax"},"outputs":[],"source":["joint_map = [(3,2),(2,20),(20,4),(4,5),(5,6),(6,7),(7,21),(7,22),(20,8),(8,9),(9,10),(10,11),(11,23),(11,24),\n","            (20,1),(1,0),(0,12),(12,13),(13,14),(14,15),(0,16),(16,17),(17,18),(18,19),(8,16),(4,12),(8,4),(16,12)]\n","\n","joint_map = val_ds.create_connection_map(joint_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"OJzG7jyh7pU_"},"outputs":[],"source":["\"\"\"\n","save_vids_dir = \"checking_vids/init\"\n","for adata in tqdm(train_dl):\n","  selected_ind = random.randint(0,adata[0].shape[0]-1)\n","  data = adata[0][selected_ind].numpy()\n","  file_id = adata[4][selected_ind].split(\".\")[0]\n","  target = id2clsname[int(adata[2][selected_ind])]\n","  vid_size = [int(adata[3][0][selected_ind]),int(adata[3][1][selected_ind])]\n","\n","  try:\n","    if not os.path.exists(f\"{save_vids_dir}/{file_id}/dataloader_out_cls_{target}.mp4\"):\n","      os.makedirs(f\"{save_vids_dir}/{file_id}\",exist_ok=True)\n","      gen_video(data, \n","                f\"{save_vids_dir}/{file_id}/dataloader_out_cls_{target}.mp4\",\n","                vid_size[0], \n","                vid_size[1],\n","                is_3d=False,\n","                mapping_list=joint_map\n","                )\n","  except ValueError:\n","    continue\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"QNhRUvwyFUQb"},"outputs":[],"source":["class norm_data(nn.Module):\n","    def __init__(self, dim=3, joints=20):\n","        super(norm_data, self).__init__()\n","\n","        self.bn = nn.BatchNorm1d(dim*joints)\n","\n","    def forward(self, x):\n","        bs, c, num_joints, step = x.size()\n","        x = x.view(bs, -1, step)\n","        x = self.bn(x)\n","        x = x.view(bs, -1, num_joints, step).contiguous()\n","        return x\n","\n","class embed(nn.Module):\n","    def __init__(self, dim=3, joint=20, hidden_dim=128, norm=True, bias=False):\n","        super(embed, self).__init__()\n","\n","        if norm:\n","            self.cnn = nn.Sequential(\n","                norm_data(dim, joint),\n","                cnn1x1(dim, 64, bias=bias),\n","                nn.ReLU(),\n","                cnn1x1(64, hidden_dim, bias=bias),\n","                nn.ReLU(),\n","            )\n","        else:\n","            self.cnn = nn.Sequential(\n","                cnn1x1(dim, 64, bias=bias),\n","                nn.ReLU(),\n","                cnn1x1(64, hidden_dim, bias=bias),\n","                nn.ReLU(),\n","            )\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        return x\n","\n","class cnn1x1(nn.Module):\n","    def __init__(self, dim1 = 3, dim2 =3, bias = True):\n","        super(cnn1x1, self).__init__()\n","        self.cnn = nn.Conv2d(dim1, dim2, kernel_size=1, bias=bias)\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        return x\n","\n","class local(nn.Module):\n","    def __init__(self, dim1 = 3, dim2 = 3, bias = False):\n","        super(local, self).__init__()\n","        self.maxpool = nn.AdaptiveMaxPool2d((1, None))\n","        self.cnn1 = nn.Conv2d(dim1, dim1, kernel_size=(1, 3), padding=(0, 1), bias=bias)\n","        self.bn1 = nn.BatchNorm2d(dim1)\n","        self.relu = nn.ReLU()\n","        self.cnn2 = nn.Conv2d(dim1, dim2, kernel_size=1, bias=bias)\n","        self.bn2 = nn.BatchNorm2d(dim2)\n","        self.dropout = nn.Dropout2d(0.2)\n","\n","    def forward(self, x1):\n","        x1 = self.maxpool(x1)\n","        x = self.cnn1(x1)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.cnn2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","\n","        return x\n","\n","class gcn_spa(nn.Module):\n","    def __init__(self, in_feature, out_feature, bias = False):\n","        super(gcn_spa, self).__init__()\n","        self.bn = nn.BatchNorm2d(out_feature)\n","        self.relu = nn.ReLU()\n","        self.w = cnn1x1(in_feature, out_feature, bias=False)\n","        self.w1 = cnn1x1(in_feature, out_feature, bias=bias)\n","\n","\n","    def forward(self, x1, g):\n","        x = x1.permute(0, 3, 2, 1).contiguous()\n","        x = g.matmul(x)\n","        x = x.permute(0, 3, 2, 1).contiguous()\n","        x = self.w(x) + self.w1(x1)\n","        x = self.relu(self.bn(x))\n","        return x\n","\n","class compute_g_spa(nn.Module):\n","    def __init__(self, dim1 = 64 *3, dim2 = 64*3, bias = False):\n","        super(compute_g_spa, self).__init__()\n","        self.dim1 = dim1\n","        self.dim2 = dim2\n","        self.g1 = cnn1x1(self.dim1, self.dim2, bias=bias)\n","        self.g2 = cnn1x1(self.dim1, self.dim2, bias=bias)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x1):\n","\n","        g1 = self.g1(x1).permute(0, 3, 2, 1).contiguous()\n","        g2 = self.g2(x1).permute(0, 3, 1, 2).contiguous()\n","        g3 = g1.matmul(g2)\n","        g = self.softmax(g3)\n","        return g\n","    \n","\n","class SGN(nn.Module):\n","    def __init__(self, num_joint, seg, hidden_size=128, bs=32, is_3d=True, train=True, bias=True, device='cpu'):\n","        super(SGN, self).__init__()\n","\n","        self.dim1 = hidden_size\n","        self.dim_unit = hidden_size // 4 \n","        self.seg = seg\n","        self.num_joint = num_joint\n","        self.bs = bs\n","\n","        if is_3d:\n","          self.spatial_dim = 3\n","        else:\n","          self.spatial_dim = 2\n","\n","        if train:\n","            self.spa = self.one_hot(bs, num_joint, self.seg)\n","            self.spa = self.spa.permute(0, 3, 2, 1).to(device)\n","            self.tem = self.one_hot(bs, self.seg, num_joint)\n","            self.tem = self.tem.permute(0, 3, 1, 2).to(device)\n","        else:\n","            self.spa = self.one_hot(32 * 5, num_joint, self.seg)\n","            self.spa = self.spa.permute(0, 3, 2, 1).to(device)\n","            self.tem = self.one_hot(32 * 5, self.seg, num_joint)\n","            self.tem = self.tem.permute(0, 3, 1, 2).to(device)\n","\n","        self.tem_embed = embed(self.seg, joint=self.num_joint, hidden_dim=self.dim_unit*4, norm=False, bias=bias)\n","        self.spa_embed = embed(num_joint, joint=self.num_joint, hidden_dim=self.dim_unit, norm=False, bias=bias)\n","        self.joint_embed = embed(self.spatial_dim, joint=self.num_joint, hidden_dim=self.dim_unit, norm=True, bias=bias)\n","        self.dif_embed = embed(self.spatial_dim, joint=self.num_joint, hidden_dim=self.dim_unit, norm=True, bias=bias)\n","        self.maxpool = nn.AdaptiveMaxPool2d([1, 1])\n","        self.cnn = local(self.dim1, self.dim1 * 2, bias=bias)\n","        self.compute_g1 = compute_g_spa(self.dim1 // 2, self.dim1, bias=bias)\n","        self.gcn1 = gcn_spa(self.dim1 // 2, self.dim1 // 2, bias=bias)\n","        self.gcn2 = gcn_spa(self.dim1 // 2, self.dim1, bias=bias)\n","        self.gcn3 = gcn_spa(self.dim1, self.dim1, bias=bias)\n","        \n","        self.embed_maxpool = nn.AdaptiveMaxPool2d([self.dim1, 2])\n","\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","\n","        nn.init.constant_(self.gcn1.w.cnn.weight, 0)\n","        nn.init.constant_(self.gcn2.w.cnn.weight, 0)\n","        nn.init.constant_(self.gcn3.w.cnn.weight, 0)\n","\n","\n","    def forward(self, input):\n","        \n","        # Dynamic Representation\n","        input = input.view((self.bs, self.seg, self.num_joint, self.spatial_dim))\n","        input = input.permute(0, 3, 2, 1).contiguous()\n","        dif = input[:, :, :, 1:] - input[:, :, :, 0:-1]\n","        dif = torch.cat([dif.new(self.bs, dif.size(1), self.num_joint, 1).zero_(), dif], dim=-1)\n","        # print(input.shape)\n","        pos = self.joint_embed(input)\n","        tem1 = self.tem_embed(self.tem)\n","        spa1 = self.spa_embed(self.spa)\n","        dif = self.dif_embed(dif)\n","        dy = pos + dif\n","        # Joint-level Module\n","        input= torch.cat([dy, spa1], 1)\n","        g = self.compute_g1(input)\n","        input = self.gcn1(input, g)\n","        input = self.gcn2(input, g)\n","        input = self.gcn3(input, g)\n","        # Frame-level Module\n","        input = input + tem1\n","        input = self.cnn(input)\n","        output_feat = torch.squeeze(input)\n","        output_feat = self.embed_maxpool(output_feat)\n","        output_feat = torch.flatten(output_feat, 1)\n","\n","        return output_feat\n","\n","    def one_hot(self, bs, spa, tem):\n","\n","        y = torch.arange(spa).unsqueeze(-1)\n","        y_onehot = torch.FloatTensor(spa, spa)\n","\n","        y_onehot.zero_()\n","        y_onehot.scatter_(1, y, 1)\n","\n","        y_onehot = y_onehot.unsqueeze(0).unsqueeze(0)\n","        y_onehot = y_onehot.repeat(bs, tem, 1, 1)\n","\n","        return y_onehot\n","\n","class SGNClassifier(nn.Module):\n","  def __init__(self,num_classes,embedding_size, *args, **kwargs) -> None:\n","      super().__init__(*args, **kwargs)\n","      self.num_classes = num_classes\n","      self.embedding_size = embedding_size\n","      self.fc = nn.Linear(self.embedding_size, self.num_classes)\n","\n","  def forward(self, input):\n","      output = self.fc(input)\n","      return output\n","    \n","class BiLSTMDecoder(nn.Module):\n","    def __init__(self,seq_len, input_size, hidden_size, linear_filters,embedding_size:int, num_layers = 1,bidirectional=True,dev=device):\n","        super(BiLSTMDecoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.dev = dev\n","        self.num_layers = num_layers\n","        self.linear_filters = linear_filters[::-1]\n","        self.embedding_size = embedding_size\n","        self.bidirectional = bidirectional\n","        self.seq_len = seq_len\n","\n","        if bidirectional:\n","            self.input_linear = nn.Linear(self.embedding_size,4*self.hidden_size)\n","        else:\n","            self.input_linear = nn.Linear(self.embedding_size,2*self.hidden_size)\n","\n","        # define LSTM layer\n","        self.layers = []\n","        # add lstm\n","        self.lstm = nn.LSTM(input_size = self.linear_filters[0], hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=bidirectional)\n","\n","                        \n","        # add linear layers \n","        if bidirectional:\n","            self.layers.append(nn.Linear(2*hidden_size,self.linear_filters[0]))\n","        else:\n","            self.layers.append(nn.Linear(hidden_size,self.linear_filters[0]))\n","\n","        for __id,layer_in in enumerate(self.linear_filters):\n","            if __id == len(linear_filters)-1:\n","                self.layers.append(nn.Linear(layer_in,self.input_size))\n","            else:\n","                self.layers.append(nn.Linear(layer_in,self.linear_filters[__id+1]))\n","\n","        self.net = nn.Sequential(*self.layers)\n","\n","        \n","        \n","\n","    def forward(self,encoder_hidden):\n","        \"\"\"\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence\n","        \"\"\"\n","        \n","        \n","        hidden_shape = encoder_hidden.shape\n","        encoder_hidden = self.input_linear(encoder_hidden)\n","        \n","        if self.bidirectional:\n","            hidden = encoder_hidden.view((-1,4,self.hidden_size))\n","            hidden = torch.transpose(hidden,1,0)\n","            h1,h2,c1,c2 = torch.unbind(hidden,0)\n","            h,c = torch.stack((h1,h2)),torch.stack((c1,c2))\n","            bs = h.size()[1]\n","        else:\n","            hidden = encoder_hidden.view((-1,2,self.hidden_size))\n","            hidden = torch.transpose(hidden,1,0)\n","            h,c = torch.unbind(hidden,0)\n","            bs = h.size()[1]\n","        \n","        dummy_input = torch.rand((bs,self.seq_len,self.hidden_size), requires_grad=True).to(self.dev)\n","        \n","        lstm_out, self.hidden = self.lstm(dummy_input,(h,c))\n","        x = self.net(lstm_out)\n","        \n","        return x\n","\n","class EncDecModel(nn.Module):\n","    def __init__(self,encoder,decoder,classifier):\n","        super(EncDecModel, self).__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.classifier = classifier\n","        \n","    def forward(self,x):\n","        embedding = self.encoder(x)\n","        classifier_out = self.classifier(embedding)\n","        decoder_out = self.decoder(embedding)\n","        \n","        return decoder_out, embedding, classifier_out\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671736,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"SxOl8YuW6f71"},"outputs":[],"source":["encoder = SGN( \n","    num_joint=config[\"model\"][\"num_joint\"], \n","    seg=config[\"model\"][\"seq_len\"], \n","    hidden_size=config[\"model\"][\"encoder_hidden_size\"], \n","    bs=batch_size, \n","    is_3d=config[\"model\"][\"is_3d\"],\n","    device = device,\n","    train=True).to(device)\n","\n","classifier = SGNClassifier(\n","    num_classes=len(class_names),\n","    embedding_size=config[\"model\"][\"embedding_size\"],\n",").to(device)\n","\n","decoder = BiLSTMDecoder(\n","    seq_len=config[\"model\"][\"seq_len\"],\n","    input_size=config[\"model\"][\"input_size\"],\n","    hidden_size=config[\"model\"][\"decoder_hidden_size\"],\n","    linear_filters=config[\"model\"][\"linear_filters\"],\n","    embedding_size=config[\"model\"][\"embedding_size\"],\n","    num_layers = config[\"model\"][\"num_layers\"],\n","    bidirectional=config[\"model\"][\"bidirectional\"],\n","    dev=config[\"model\"][\"dev\"]).to(device)\n","\n","bilstm_model = EncDecModel(\n","    encoder = encoder,\n","    decoder = decoder,\n","    classifier = classifier\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"RETBAwj46i3Z"},"outputs":[],"source":["bilstm_model.to(device);"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"8t79v6xM6wx7"},"outputs":[],"source":["label_map = [(k,v) for k,v in id2clsname.items()]\n","labelToId = {x[0]: i for i, x in enumerate(label_map)}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"Mfa8NjY57En3"},"outputs":[],"source":["def combined_loss(pred_sequence,pred_label,true_sequence,true_label,loss_module,alpha_target=1,alpha_recon=1):\n","    recon_loss = alpha_recon*loss_module[\"reconstruction_loss\"](pred_sequence,true_sequence)\n","    tar_loss = alpha_target*loss_module[\"target_loss\"](pred_label,true_label)\n","    loss =  recon_loss + tar_loss\n","\n","    #print(alpha_recon*loss_module[\"reconstruction_loss\"](pred_sequence,true_sequence))\n","    #print(alpha_target*loss_module[\"target_loss\"](pred_label,true_label))\n","\n","    return loss, {\n","        \"reconstruction_loss\":recon_loss.item(),\n","        \"target_loss\":tar_loss.item()\n","    }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"brTkTW9BEa3i"},"outputs":[],"source":["optimizer = torch.optim.Adam(bilstm_model.parameters(), lr=config[\"lr\"], weight_decay=0.01)\n","std_loss = {\n","    \"reconstruction_loss\" :nn.L1Loss(),\n","    \"target_loss\" :nn.CrossEntropyLoss()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"RUigg8dNcWJO"},"outputs":[],"source":["def plot_curves(df):\n","    df['loss'] = df['loss']/df['samples']\n","    df['feat. loss'] = df['feat. loss']/df['samples']\n","    df['classi. loss'] = df['classi. loss']/df['samples']\n","    \n","    fig, axs = plt.subplots(nrows=4)\n","    sns.lineplot(data=df, x='epoch', y='loss', hue='phase', marker='o', ax=axs[2]).set(title=\"Loss\")\n","    sns.lineplot(data=df, x='epoch', y='feat. loss', hue='phase', marker='o', ax=axs[0]).set(title=\"Feature Loss\")\n","    sns.lineplot(data=df, x='epoch', y='classi. loss', hue='phase', marker='o', ax=axs[1]).set(title=\"Classification Loss\")\n","    sns.lineplot(data=df, x='epoch', y='accuracy', hue='phase', marker='o', ax=axs[3]).set(title=\"Accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"DksWHRbgDgPQ"},"outputs":[],"source":["def train_step(model, dataloader, optimizer, loss_module, device, class_names):\n","    model = model.train()\n","    epoch_loss = 0  # total loss of epoch\n","    total_samples = 0  # total samples in epoch\n","    targets = []\n","    predicts = []\n","\n","    with tqdm(dataloader, unit=\"batch\", desc=\"train\") as tepoch:\n","          for input_sequence,target_sequence,target_action,target_vid_size, _ in tepoch:\n","            input_sequence = input_sequence.to(device)\n","            target_sequence = target_sequence.to(device)\n","            target_action = target_action.to(device)\n","            \n","\n","            # Zero gradients, perform a backward pass, and update the weights.\n","            optimizer.zero_grad()\n","            # forward track history if only in train\n","            with torch.set_grad_enabled(True):\n","            # with autocast():\n","              predicted_sequence, _, predicted_label  = model(input_sequence)\n","            \n","            # loss,loss_detail = combined_loss(predicted_sequence,predicted_label, target_sequence, target_action,std_loss)\n","            recon_loss = loss_module[\"reconstruction_loss\"](predicted_sequence,target_sequence)\n","            tar_loss = loss_module[\"target_loss\"](predicted_label,target_action)\n","            loss =  (1-config['alpha_target'])*recon_loss + config['alpha_target']*tar_loss\n","            loss_detail = {\"reconstruction_loss\":recon_loss.item(),\"target_loss\":tar_loss.item()}\n","\n","            class_output = torch.argmax(predicted_label,dim=1)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            metrics = {\"loss\": loss.item()}\n","            with torch.no_grad():\n","                total_samples += len(target_action)\n","                epoch_loss += loss.item()  # add total loss of batch\n","\n","            # convert feature vector into action class using cosine\n","            pred_class = class_output.cpu().detach().numpy()\n","            metrics[\"accuracy\"] = accuracy_score(y_true=target_action.cpu().detach().numpy(), y_pred=pred_class)\n","            tepoch.set_postfix(metrics)\n","\n","            targets.append(target_action.cpu().detach().numpy())\n","            predicts.append(pred_class)\n","\n","    \n","    predicts = np.concatenate(predicts)\n","    targets = np.concatenate(targets)\n","    #train_metrics = action_evaluator(predicts,targets,class_names=list(clsname2id.keys()),print_report=False)\n","\n","    epoch_loss = epoch_loss / total_samples  # average loss per sample for whole epoch\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"TmXFlJJdEN9N"},"outputs":[],"source":["def eval_step(model, dataloader,loss_module, device, class_names,  print_report=False, show_plot=False):\n","    model = model.eval()\n","    epoch_loss = 0  # total loss of epoch\n","    total_samples = 0  # total samples in epoch\n","    per_batch = {'targets': [], 'predictions': [], 'metrics': []}\n","    metrics = {\"samples\": 0, \"loss\": 0, \"feat. loss\": 0, \"classi. loss\": 0}\n","\n","    with torch.no_grad():\n","      with tqdm(dataloader, unit=\"batch\", desc=\"eval\") as tepoch:\n","        for input_sequence,target_sequence,target_action,target_vid_size,_ in tepoch:\n","\n","            input_sequence = input_sequence.to(device)\n","            target_sequence = target_sequence.to(device)\n","            target_action = target_action.to(device)\n","\n","            # forward track history if only in train\n","            with torch.set_grad_enabled(False):\n","            # with autocast():\n","                predicted_sequence,_,predicted_label  = model(input_sequence)\n","            # loss,loss_detail = combined_loss(predicted_sequence,predicted_label, target_sequence, target_action,std_loss)\n","            recon_loss = loss_module[\"reconstruction_loss\"](predicted_sequence,target_sequence)\n","            tar_loss = loss_module[\"target_loss\"](predicted_label,target_action)\n","            loss =  (1-config['alpha_target'])*recon_loss + config['alpha_target']*tar_loss\n","            loss_detail = {\"reconstruction_loss\":recon_loss.item(),\"target_loss\":tar_loss.item()}\n","            \n","            pred_action = torch.argmax(predicted_label,dim=1)\n","\n","            with torch.no_grad():\n","                metrics['samples'] += len(target_action)\n","                metrics['loss'] += loss.item()  # add total loss of batch\n","                metrics['feat. loss'] += loss_detail[\"reconstruction_loss\"]\n","                metrics['classi. loss'] += loss_detail[\"target_loss\"]\n","\n","            per_batch['targets'].append(target_action.cpu().numpy())\n","            per_batch['predictions'].append(pred_action.cpu().numpy())\n","            per_batch['metrics'].append([loss.cpu().numpy()])\n","\n","            tepoch.set_postfix({\"loss\": loss.item()})\n","\n","    all_preds = np.concatenate(per_batch[\"predictions\"])\n","    all_targets = np.concatenate(per_batch[\"targets\"])\n","    metrics_dict = action_evaluator(y_pred=all_preds, y_true=all_targets, class_names=class_names, print_report=print_report, show_plot=show_plot)\n","    metrics_dict.update(metrics)\n","    return metrics_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1684244671737,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"6QMFOxCZE0T2"},"outputs":[],"source":["def log(fold, phase, metrics):\n","    for m, v in metrics.items():\n","        if fold == 'global':\n","            run[f'global/{m}'].log(v)\n","        else:\n","            run[f\"Fold-{fold}/{phase}/{m}\"].log(v)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671738,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"gEfzDnIP81qB"},"outputs":[],"source":["start_epoch = 20\n","#model_params, model_config, config = get_config(f\"/content/drive/MyDrive/22_FYP42 - Zero-shot Explainable HAR/Devin/SkeletonAE/model_saves/temp_{model_ident}/{start_epoch}__{unique_iden}.pt\")\n","#bilstm_model.load_state_dict(model_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyUEFUlp7HOt","executionInfo":{"status":"aborted","timestamp":1684244671738,"user_tz":-330,"elapsed":15,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}}},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","\n","best_model_wts = copy.deepcopy(bilstm_model.state_dict())\n","best_acc = 0.0\n","show_interval = 10\n","\n","train_data = []\n","for epoch in tqdm(range(start_epoch+1, start_epoch+config[\"n_epochs\"] + 1), desc='Training Epoch', leave=False):\n","  \n","  train_metrics = train_step(bilstm_model, train_dl, optimizer, std_loss, device, class_names)\n","  train_metrics['epoch'] = epoch\n","  train_metrics['phase'] = 'train'\n","  train_data.append(train_metrics)\n","  log(epoch, 'train', train_metrics)\n","  \n","  if epoch % 10 == 0:\n","    eval_metrics = eval_step(bilstm_model, val_dl,std_loss, device, class_names,  print_report=True, show_plot=True)\n","  else:\n","    eval_metrics = eval_step(bilstm_model, val_dl,std_loss, device, class_names,  print_report=False, show_plot=False)\n","  eval_metrics['epoch'] = epoch \n","  eval_metrics['phase'] = 'valid'\n","  train_data.append(eval_metrics)\n","  log(epoch, 'valid', eval_metrics)\n","\n","  if epoch%10 == 0:\n","    save_model(\n","        bilstm_model, \n","        f\"temp_{model_ident}\", \n","        f\"{epoch}__{unique_iden}\",\n","         models_saves, \n","         config)\n","    \n","  if eval_metrics['accuracy'] > best_acc:\n","    best_model = copy.deepcopy(bilstm_model.state_dict())\n","  \n","train_df = pd.DataFrame().from_records(train_data)\n","plot_curves(train_df)\n","\n","# replace by best model \n","bilstm_model.load_state_dict(best_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExxCQYfszQ0K","executionInfo":{"status":"aborted","timestamp":1684244671738,"user_tz":-330,"elapsed":15,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}}},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","\n","best_model_wts = copy.deepcopy(bilstm_model.state_dict())\n","best_acc = 0.0\n","show_interval = 10\n","\n","train_data = []\n","for epoch in tqdm(range(start_epoch+1, start_epoch+config[\"n_epochs\"] + 1), desc='Training Epoch', leave=False):\n","  \n","  train_metrics = train_step(bilstm_model, train_dl, optimizer, std_loss, device, class_names)\n","  train_metrics['epoch'] = epoch\n","  train_metrics['phase'] = 'train'\n","  train_data.append(train_metrics)\n","  log(epoch, 'train', train_metrics)\n","  \n","  if epoch % 10 == 0:\n","    eval_metrics = eval_step(bilstm_model, val_dl,std_loss, device, class_names,  print_report=True, show_plot=True)\n","  else:\n","    eval_metrics = eval_step(bilstm_model, val_dl,std_loss, device, class_names,  print_report=False, show_plot=False)\n","  eval_metrics['epoch'] = epoch \n","  eval_metrics['phase'] = 'valid'\n","  train_data.append(eval_metrics)\n","  log(epoch, 'valid', eval_metrics)\n","\n","  if epoch%10 == 0:\n","    save_model(\n","        bilstm_model, \n","        f\"temp_{model_ident}\", \n","        f\"{epoch}__{unique_iden}\",\n","         models_saves, \n","         config)\n","    \n","  if eval_metrics['accuracy'] > best_acc:\n","    best_model = copy.deepcopy(bilstm_model.state_dict())\n","  \n","train_df = pd.DataFrame().from_records(train_data)\n","plot_curves(train_df)\n","\n","# replace by best model \n","bilstm_model.load_state_dict(best_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1684244671738,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"},"user_tz":-330},"id":"xwRnz2rmqH7z"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}