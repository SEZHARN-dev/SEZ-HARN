{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"EnmESXTBv5qX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkIfhXqxWhOw","executionInfo":{"status":"ok","timestamp":1682831679945,"user_tz":-330,"elapsed":8830,"user":{"displayName":"Pathirage Nipun Deelaka","userId":"00264959805100472870"}},"outputId":"5fe86b73-5fab-4a44-d471-da6958e47200"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-8549c943defc>:16: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm\n"]}],"source":["import os\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import math\n","\n","from itertools import product\n","import torch \n","from torch import nn \n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm.autonotebook import tqdm\n","import itertools\n","import random\n","import copy\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","import cv2\n","import json\n","from sklearn.model_selection import train_test_split\n","from functools import partial\n","from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"]},{"cell_type":"code","source":["class BiLSTMDecoder(nn.Module):\n","    def __init__(self,seq_len, input_size, hidden_size, linear_filters,embedding_size:int, num_layers = 1,bidirectional=True,device=\"cpu\"):\n","        super(BiLSTMDecoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.device = device\n","        self.num_layers = num_layers\n","        self.linear_filters = linear_filters[::-1]\n","        self.embedding_size = embedding_size\n","        self.bidirectional = bidirectional\n","        self.seq_len = seq_len\n","\n","        if bidirectional:\n","            self.input_linear = nn.Linear(self.embedding_size,4*self.hidden_size)\n","        else:\n","            self.input_linear = nn.Linear(self.embedding_size,2*self.hidden_size)\n","\n","        # define LSTM layer\n","        self.layers = []\n","        # add lstm\n","        self.lstm = nn.LSTM(input_size = self.linear_filters[0], hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=bidirectional)\n","\n","                        \n","        # add linear layers \n","        if bidirectional:\n","            self.layers.append(nn.Linear(2*hidden_size,self.linear_filters[0]))\n","        else:\n","            self.layers.append(nn.Linear(hidden_size,self.linear_filters[0]))\n","\n","        for __id,layer_in in enumerate(self.linear_filters):\n","            if __id == len(linear_filters)-1:\n","                self.layers.append(nn.Linear(layer_in,self.input_size))\n","            else:\n","                self.layers.append(nn.Linear(layer_in,self.linear_filters[__id+1]))\n","\n","        self.net = nn.Sequential(*self.layers)\n","\n","        \n","        \n","\n","    def forward(self,encoder_hidden):\n","        \"\"\"\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence\n","        \"\"\"\n","        \n","        \n","        hidden_shape = encoder_hidden.shape\n","        encoder_hidden = self.input_linear(encoder_hidden)\n","        \n","        if self.bidirectional:\n","            hidden = encoder_hidden.view((-1,4,self.hidden_size))\n","            hidden = torch.transpose(hidden,1,0)\n","            h1,h2,c1,c2 = torch.unbind(hidden,0)\n","            h,c = torch.stack((h1,h2)),torch.stack((c1,c2))\n","            bs = h.size()[1]\n","        else:\n","            hidden = encoder_hidden.view((-1,2,self.hidden_size))\n","            hidden = torch.transpose(hidden,1,0)\n","            h,c = torch.unbind(hidden,0)\n","            bs = h.size()[1]\n","        \n","        dummy_input = torch.rand((bs,self.seq_len,self.hidden_size), requires_grad=True).to(self.device)\n","        \n","        lstm_out, self.hidden = self.lstm(dummy_input,(h,c))\n","        x = self.net(lstm_out)\n","        \n","        return x"],"metadata":{"id":"-bf8V7t3iebz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_config(file_loc,device):\n","    file = torch.load(file_loc,map_location=device)\n","    return file[\"model_state_dict\"], file[\"model_config\"], file[\"config\"]\n","\n","model_params, model_config, config = get_config(\n","    \"/content/drive/MyDrive/22_FYP42 - Zero-shot Explainable HAR/Devin/SkeletonAE/model_saves/temp_NTURGB120_skeleton_SGN_classifier_emb1d/40__epoch50_emb1024_xy_decoder.pt\",\n","    torch.device(\"cpu\")\n","    )"],"metadata":{"id":"Rj07G0g7mOqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvwkIPn9mcYD","executionInfo":{"status":"ok","timestamp":1682831031037,"user_tz":-330,"elapsed":4,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"8a19a795-e8f1-4473-9483-f15e2dba41d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_epochs': 20,\n"," 'model_name': 'BidirectionalLSTM',\n"," 'model': {'num_joint': 12,\n","  'seq_len': 60,\n","  'decoder_hidden_size': 1024,\n","  'linear_filters': [128, 256, 512, 1024],\n","  'embedding_size': 1024,\n","  'num_classes': 82,\n","  'num_layers': 1,\n","  'is_3d': False,\n","  'bidirectional': True,\n","  'batch_size': 32,\n","  'dev': device(type='cuda'),\n","  'encoder_hidden_size': 512,\n","  'input_size': 24},\n"," 'lr': 0.0001,\n"," 'alpha_target': 0.9}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["decoder = BiLSTMDecoder(\n","    seq_len=60,\n","    input_size=24,\n","    hidden_size=256,\n","    linear_filters=[64, 128, 200, 256],\n","    embedding_size=512,\n","    num_layers = 2,\n","    bidirectional=True,\n","    dev=torch.device(\"cpu\")\n","    )"],"metadata":{"id":"SxOl8YuW6f71","executionInfo":{"status":"ok","timestamp":1682832272032,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Pathirage Nipun Deelaka","userId":"00264959805100472870"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# decoder.load_state_dict(model_params)"],"metadata":{"id":"mz8RDzK-mFhr","executionInfo":{"status":"ok","timestamp":1682832276654,"user_tz":-330,"elapsed":27,"user":{"displayName":"Pathirage Nipun Deelaka","userId":"00264959805100472870"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["decoder(torch.rand((32,512))).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"Ftmsh7z8SjcU","executionInfo":{"status":"error","timestamp":1682832276655,"user_tz":-330,"elapsed":26,"user":{"displayName":"Pathirage Nipun Deelaka","userId":"00264959805100472870"}},"outputId":"46d62e00-d92e-4e77-fc6d-a436905559e9"},"execution_count":9,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-713f1f6904cf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-5d0778088e69>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_hidden)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    729\u001b[0m                            ):\n\u001b[1;32m    730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0m\u001b[1;32m    732\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[1;32m    733\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    237\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (4, 32, 256), got [2, 32, 256]"]}]},{"cell_type":"code","source":["decoder(torch.rand((32,512)))"],"metadata":{"id":"YQa36GK1m7ZG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682831989921,"user_tz":-330,"elapsed":513,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"e04dee43-a9aa-4d2c-f12d-bfcb1322e42a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.0337,  0.0506, -0.0427,  ...,  0.0586,  0.0806, -0.1121],\n","         [ 0.0347,  0.0420, -0.0460,  ...,  0.0573,  0.0773, -0.1174],\n","         [ 0.0338,  0.0467, -0.0415,  ...,  0.0622,  0.0726, -0.1183],\n","         ...,\n","         [ 0.0317,  0.0453, -0.0459,  ...,  0.0679,  0.0797, -0.1155],\n","         [ 0.0320,  0.0495, -0.0406,  ...,  0.0613,  0.0745, -0.1157],\n","         [ 0.0348,  0.0519, -0.0459,  ...,  0.0548,  0.0758, -0.1201]],\n","\n","        [[ 0.0407,  0.0497, -0.0440,  ...,  0.0596,  0.0719, -0.1142],\n","         [ 0.0400,  0.0440, -0.0406,  ...,  0.0634,  0.0719, -0.1156],\n","         [ 0.0363,  0.0440, -0.0380,  ...,  0.0603,  0.0738, -0.1206],\n","         ...,\n","         [ 0.0334,  0.0468, -0.0444,  ...,  0.0633,  0.0805, -0.1250],\n","         [ 0.0352,  0.0495, -0.0404,  ...,  0.0557,  0.0776, -0.1248],\n","         [ 0.0378,  0.0461, -0.0480,  ...,  0.0500,  0.0768, -0.1221]],\n","\n","        [[ 0.0424,  0.0481, -0.0425,  ...,  0.0598,  0.0732, -0.1109],\n","         [ 0.0411,  0.0464, -0.0447,  ...,  0.0636,  0.0782, -0.1127],\n","         [ 0.0415,  0.0406, -0.0401,  ...,  0.0653,  0.0713, -0.1150],\n","         ...,\n","         [ 0.0362,  0.0465, -0.0497,  ...,  0.0602,  0.0729, -0.1178],\n","         [ 0.0322,  0.0434, -0.0492,  ...,  0.0599,  0.0762, -0.1196],\n","         [ 0.0319,  0.0459, -0.0465,  ...,  0.0555,  0.0729, -0.1206]],\n","\n","        ...,\n","\n","        [[ 0.0402,  0.0606, -0.0465,  ...,  0.0515,  0.0759, -0.1142],\n","         [ 0.0380,  0.0520, -0.0426,  ...,  0.0620,  0.0762, -0.1166],\n","         [ 0.0387,  0.0482, -0.0419,  ...,  0.0673,  0.0749, -0.1200],\n","         ...,\n","         [ 0.0408,  0.0454, -0.0394,  ...,  0.0617,  0.0719, -0.1183],\n","         [ 0.0363,  0.0426, -0.0368,  ...,  0.0643,  0.0725, -0.1199],\n","         [ 0.0339,  0.0479, -0.0413,  ...,  0.0562,  0.0750, -0.1204]],\n","\n","        [[ 0.0426,  0.0407, -0.0352,  ...,  0.0579,  0.0746, -0.1117],\n","         [ 0.0400,  0.0433, -0.0385,  ...,  0.0608,  0.0752, -0.1173],\n","         [ 0.0419,  0.0396, -0.0375,  ...,  0.0617,  0.0768, -0.1186],\n","         ...,\n","         [ 0.0374,  0.0429, -0.0445,  ...,  0.0589,  0.0763, -0.1224],\n","         [ 0.0411,  0.0484, -0.0440,  ...,  0.0580,  0.0727, -0.1235],\n","         [ 0.0359,  0.0421, -0.0472,  ...,  0.0544,  0.0720, -0.1194]],\n","\n","        [[ 0.0497,  0.0545, -0.0421,  ...,  0.0567,  0.0748, -0.1124],\n","         [ 0.0428,  0.0522, -0.0402,  ...,  0.0657,  0.0776, -0.1153],\n","         [ 0.0423,  0.0490, -0.0417,  ...,  0.0638,  0.0717, -0.1143],\n","         ...,\n","         [ 0.0433,  0.0452, -0.0348,  ...,  0.0591,  0.0788, -0.1238],\n","         [ 0.0478,  0.0441, -0.0390,  ...,  0.0602,  0.0745, -0.1201],\n","         [ 0.0401,  0.0449, -0.0404,  ...,  0.0547,  0.0781, -0.1222]]],\n","       grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["decoder.to(torch.device(\"cuda\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9MCDlkljw-f","executionInfo":{"status":"ok","timestamp":1682831937151,"user_tz":-330,"elapsed":2,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"bab69d14-7e14-459b-964b-cac0b9cade5a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BiLSTMDecoder(\n","  (input_linear): Linear(in_features=512, out_features=1024, bias=True)\n","  (lstm): LSTM(256, 256, batch_first=True, bidirectional=True)\n","  (net): Sequential(\n","    (0): Linear(in_features=512, out_features=256, bias=True)\n","    (1): Linear(in_features=256, out_features=128, bias=True)\n","    (2): Linear(in_features=128, out_features=24, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["decoder.dev = torch.device(\"cuda\")"],"metadata":{"id":"MpiDLLpFkUsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder(torch.rand((32,512)).to(torch.device(\"cuda\"))).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1TMhg32j8mT","executionInfo":{"status":"ok","timestamp":1682831946522,"user_tz":-330,"elapsed":448,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"8082c411-b3e6-40df-c5c6-bb117f54f2c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 60, 24])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["decoder(torch.rand((32,512)).to(torch.device(\"cuda\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoCKE5EakKz4","executionInfo":{"status":"ok","timestamp":1682831953082,"user_tz":-330,"elapsed":3,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"a3771ed0-56ec-401b-8e26-ff47f82d9e0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-6.7592e-02, -2.7603e-03,  7.8295e-02,  ..., -4.9465e-02,\n","           1.5016e-02, -1.1841e-02],\n","         [-7.5019e-02, -1.1389e-02,  8.9882e-02,  ..., -5.3531e-02,\n","           2.6554e-02, -2.5699e-02],\n","         [-7.1981e-02, -7.9594e-03,  9.3056e-02,  ..., -4.1591e-02,\n","           2.2789e-02, -2.6175e-02],\n","         ...,\n","         [-4.0325e-02, -4.6214e-03,  1.0823e-01,  ..., -3.3361e-02,\n","           7.5475e-03, -1.1074e-02],\n","         [-4.1810e-02,  3.3957e-03,  1.2069e-01,  ..., -5.2681e-02,\n","           2.7092e-02, -1.7787e-02],\n","         [-5.3446e-02,  1.0119e-02,  1.2551e-01,  ..., -5.2466e-02,\n","           3.2189e-02, -1.1812e-02]],\n","\n","        [[-8.2152e-02, -1.9085e-02,  7.7862e-02,  ..., -2.7000e-02,\n","           3.1774e-02, -1.3102e-02],\n","         [-7.2895e-02, -5.1334e-03,  8.7359e-02,  ..., -3.0714e-02,\n","           2.4972e-02, -1.9598e-02],\n","         [-6.9622e-02, -2.1240e-02,  8.4317e-02,  ..., -2.4805e-02,\n","           1.8852e-02, -1.6728e-02],\n","         ...,\n","         [-5.8537e-02,  3.8848e-03,  1.1039e-01,  ..., -6.0787e-02,\n","           2.8917e-02, -2.5323e-02],\n","         [-4.1987e-02, -1.0634e-02,  1.1117e-01,  ..., -5.6064e-02,\n","           2.3759e-02, -2.5926e-02],\n","         [-4.2357e-02, -1.1716e-03,  1.2260e-01,  ..., -4.9007e-02,\n","           2.3937e-02, -2.8515e-02]],\n","\n","        [[-6.9544e-02, -7.3452e-03,  7.1056e-02,  ..., -3.4916e-02,\n","           1.7015e-02, -3.0343e-02],\n","         [-6.7471e-02,  1.1217e-03,  8.4331e-02,  ..., -3.7271e-02,\n","           1.1554e-02, -1.3068e-02],\n","         [-6.4844e-02,  1.6694e-04,  9.5267e-02,  ..., -4.4520e-02,\n","           2.5010e-02, -7.2790e-03],\n","         ...,\n","         [-6.0418e-02, -1.1597e-02,  1.1719e-01,  ..., -3.5347e-02,\n","           1.5780e-02, -2.3933e-02],\n","         [-7.2606e-02, -5.2507e-03,  1.1464e-01,  ..., -4.0567e-02,\n","           2.0580e-02, -4.7644e-03],\n","         [-6.3415e-02,  1.0117e-02,  1.2579e-01,  ..., -6.0856e-02,\n","           4.6722e-02, -3.7716e-03]],\n","\n","        ...,\n","\n","        [[-7.1283e-02, -1.5345e-02,  8.1041e-02,  ..., -6.1446e-02,\n","           3.1464e-02, -1.3367e-02],\n","         [-7.2991e-02, -1.6977e-03,  9.4172e-02,  ..., -5.4821e-02,\n","           3.7877e-02, -4.1180e-02],\n","         [-6.7490e-02, -1.1571e-02,  9.0628e-02,  ..., -3.9990e-02,\n","           3.2600e-02, -4.3613e-02],\n","         ...,\n","         [-6.8122e-02, -1.0245e-02,  1.0810e-01,  ..., -4.7534e-02,\n","           2.7584e-02, -2.4642e-02],\n","         [-7.1157e-02, -8.6551e-03,  1.3975e-01,  ..., -6.3311e-02,\n","           2.7274e-02, -1.2027e-02],\n","         [-6.6583e-02, -1.4927e-03,  1.3169e-01,  ..., -7.0549e-02,\n","           2.5847e-02, -2.4273e-03]],\n","\n","        [[-5.4695e-02, -1.2915e-04,  9.4424e-02,  ..., -2.8389e-02,\n","           1.8595e-02, -2.0116e-02],\n","         [-5.0701e-02,  2.2938e-03,  9.4112e-02,  ..., -4.0084e-02,\n","           3.4334e-02, -1.4669e-02],\n","         [-5.1948e-02, -4.3500e-03,  1.0422e-01,  ..., -2.8379e-02,\n","           3.4053e-02, -2.2593e-02],\n","         ...,\n","         [-7.6378e-02, -4.6669e-03,  1.1358e-01,  ..., -3.2147e-02,\n","           1.8153e-02, -2.0266e-02],\n","         [-8.7233e-02, -1.7388e-02,  1.2482e-01,  ..., -2.7473e-02,\n","           3.8544e-02, -1.3685e-02],\n","         [-7.4028e-02, -1.8430e-02,  1.2201e-01,  ..., -4.4212e-02,\n","           3.8133e-02, -1.3862e-02]],\n","\n","        [[-6.8607e-02, -1.2501e-02,  7.4274e-02,  ..., -5.7524e-02,\n","           1.4366e-02, -1.6917e-02],\n","         [-6.9734e-02, -1.2449e-02,  8.8220e-02,  ..., -3.8510e-02,\n","           2.1919e-02, -2.9880e-02],\n","         [-5.9501e-02, -6.9809e-03,  8.8277e-02,  ..., -4.0890e-02,\n","           1.7312e-02, -2.3711e-02],\n","         ...,\n","         [-7.2327e-02, -2.1889e-02,  9.0488e-02,  ..., -4.0652e-02,\n","           1.9818e-02, -1.8614e-02],\n","         [-6.4172e-02, -1.0956e-02,  1.0170e-01,  ..., -3.0377e-02,\n","           2.2275e-02, -1.7374e-02],\n","         [-5.5440e-02,  1.2927e-02,  1.2884e-01,  ..., -4.3294e-02,\n","           4.5880e-02, -7.4446e-04]]], device='cuda:0',\n","       grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"Qd_Y0whwkjA4"},"execution_count":null,"outputs":[]}]}